log:
  version: 1
  disable_existing_loggers: False
  root:
    level: INFO
    handlers:
      - stderr
      - stdout
  handlers:
    stderr:
      class: logging.StreamHandler
      level: WARNING
      formatter: default
      stream: ext://sys.stderr
    stdout:
      class: logging.StreamHandler
      level: DEBUG
      formatter: default
      stream: ext://sys.stdout
  formatters:
    default:
      format: "%(asctime)s %(levelname)s [%(name)s] %(message)s"

global:
  busy_timeout: 60

message_stream:
  write: tcp://127.0.0.1:5650
  read: tcp://127.0.0.1:5651

audio_to_message:
  input_device:
    # name: Device Name
  silence_threshold: 0.2
  silence_duration: 0.2
  min_buffer_size: 48000
  max_buffer_size: 240000
  min_volume: 0.3
  whisper:
    model: base
    device: cuda
    prompt_length: 128
    decoding_options:
      task: transcribe
      compression_ratio_threshold: 1.1
      logprob_threshold: -0.75
      temperature: 0
      no_speech_threshold: 0.5
      condition_on_previous_text: true
      # language: en
      # fp16: false
    blacklist: []
    max_temperature: 0.5
  vad:
    pipeline:
      segmentation: pyannote/segmentation
      device: cpu
    hyper_parameters:
      onset: 0.5
      offset: 0.5
      min_duration_on: 0.0
      min_duration_off: 0.0

chat_engine:
  min_interval: 15
  sleep_after_completion: 10
  history:
    max_count: 5
  device: cuda
  # model: path/to/your/trained/model
  model: gpt2
  # tokenizer: gpt2
  generation_config: # https://huggingface.co/transformers/main_classes/model.html?highlight=generate#transformers.PreTrainedModel.generate
    # max_length: 20 #20
    # min_length: 10 #10
    do_sample: true #false
    # early_stopping: true #false
    # num_beams: 2 #1
    # temperature: 1.0
    # top_k: 100 #50
    # top_p: 0.95 #1.0
    # length_penalty: 0.1 #1.0
    # no_repeat_ngram_size: 2 #0
    # encoder_no_repeat_ngram_size: 0 #0
    bad_words_ids:
      - [0] # <unk>
    # max_time: 30 #null
    # attention_mask: [[long tensor]]
    # use_cache: true #true
    # num_beam_groups : 1 #1
    # diversity_penalty: 0.0 #0.0
    # prefix_allowed_tokens_fn: # Callable[[int, torch.Tensor]. List[int]]
    # output_attentions: false #false
    # output_hidden_states: false #false
    # output_scores: false #false
    # forced_bos_token_id: int
    # forced_eos_token_id: int
    remove_invalid_values: true
    pad_token_id: 3
    min_new_tokens: 1
    max_new_tokens: 60
  message_formats:
    user: <user>{}
    assistant: <ai>{}
  suffix_messages:
    - <ai>
  message_separator: "</s><s>"
  stop_pattern: </?s>|<user>|<ai>
  max_loss: 8

message_to_speak:
  talk_pattern: (.*)
  remove_pattern: <req>( [A-Z]+)*|<res>|<extra_id_-[0-9]>( [A-Z]+)*
  output_device:
    # name: Device Name
  english_kana_dict: ./data/bep-eng/bep-eng.csv
  split_pattern: (?<=\.[^0-9])|(?<=[。!?！？])
  engine: voicevox
  voicevox:
    base_url: http://localhost:50021
    speaker: 0
  rvc:
    hubert: ./models/rvc/hubert_base.pt
    model: ./path/to/model.pth
    is_half: true
    quality: 1
    f0_up_key: 0
    f0_method: pm

neos_connector:
  websocket:
    host: "127.0.0.1"
    port: 5556
  state_timeout: 30
  max_interval: 30
  expressions:
    default: None

train:
  base_model: gpt2
  csv_file: ./path/to/data.csv
  generate_pairs: true
  eval_ratio: 0
  data_collator:
    mlm: false
  training_args:
    output_dir: ./path/to/model/
    overwrite_output_dir: true
    num_train_epochs: 2
    per_device_train_batch_size: 4
    logging_steps: 10
    save_steps: 100
    save_strategy: epoch
    resume_from_checkpoint: false
  test_inputs:
    - <s><user>Hello.</s><s><ai>
    - <s><user>Nice too meet you.</s><s><ai>
    - <s><user>Introduce yourself.</s><s><ai>
